# Open CodeAI .env example file
# Copy this file to .env for your setup (cp .env.example .env)

# === LLM/vLLM Engine ===
VLLM_ENDPOINT=http://localhost:8000/v1
VLLM_API_KEY=your-vllm-api-key
VLLM_MODEL_ID=Qwen2.5-Coder-32B-Instruct

# === Server ===
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO

# === Project Info ===
PROJECT_NAME=open-codeai
VERSION=1.0.0
ENVIRONMENT=development
DEBUG=True

# === Vector DB (FAISS, etc.) ===
# No installation/config needed, managed internally
VECTOR_DB_PORT=9000  # (set port if needed, default 9000)

# === Graph DB (NetworkX/Neo4j) ===
# No installation/config needed, managed internally
GRAPH_DB_PORT=7687  # (set port if needed, default 7687)

# === Other (optional) ===
CORS_ORIGINS=http://localhost:3000,http://localhost:8080
GPU_MEMORY_FRACTION=0.7
USE_MIXED_PRECISION=True
API_KEY=open-codeai-local-key

# === OpenRouter (Cloud LLM Fallback) ===
OPENROUTER_API_BASE=https://openrouter.ai/api/v1
OPENROUTER_API_KEY=your-openrouter-api-key
OPENROUTER_MODEL=qwen/qwen-2.5-coder-32b-instruct:free
# OPENROUTER_MAX_TOKENS=4096
# OPENROUTER_TEMPERATURE=0.1