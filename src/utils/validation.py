"""
Open CodeAI - ì‹œìŠ¤í…œ ê²€ì¦ ë° ì§„ë‹¨ ëª¨ë“ˆ
ì™„ì „í•œ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ë° ë¬¸ì œ ì§„ë‹¨ ê¸°ëŠ¥
"""
import os
import sys
import json
import time
import asyncio
import subprocess
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from datetime import datetime
import platform
import psutil

def validate_model_path(path: str) -> bool:
    """ëª¨ë¸ ê²½ë¡œ ê²€ì¦"""
    try:
        model_path = Path(path)
        if not model_path.exists():
            return False
        
        # í•„ìˆ˜ ëª¨ë¸ íŒŒì¼ë“¤ í™•ì¸
        required_files = ['config.json']
        optional_files = [
            'pytorch_model.bin', 'model.safetensors', 
            'pytorch_model.safetensors', 'tokenizer.json',
            'tokenizer_config.json', 'vocab.txt'
        ]
        
        # config.jsonì€ í•„ìˆ˜
        if not (model_path / 'config.json').exists():
            return False
        
        # ìµœì†Œ í•˜ë‚˜ì˜ ëª¨ë¸ íŒŒì¼ì€ ìˆì–´ì•¼ í•¨
        has_model_file = any(
            (model_path / file).exists() for file in optional_files
        )
        
        return has_model_file
        
    except Exception:
        return False

def validate_config(config: Dict[str, Any]) -> Dict[str, Any]:
    """ì„¤ì • íŒŒì¼ ê²€ì¦"""
    validation_result = {
        'valid': True,
        'errors': [],
        'warnings': [],
        'recommendations': []
    }
    
    try:
        # í•„ìˆ˜ ì„¹ì…˜ í™•ì¸
        required_sections = ['project', 'server']
        for section in required_sections:
            if section not in config:
                validation_result['errors'].append(f"í•„ìˆ˜ ì„¹ì…˜ ëˆ„ë½: {section}")
                validation_result['valid'] = False
        
        # í”„ë¡œì íŠ¸ ì„¤ì • ê²€ì¦
        if 'project' in config:
            project = config['project']
            if 'max_files' in project:
                max_files = project['max_files']
                if max_files > 50000:
                    validation_result['warnings'].append(
                        f"max_filesê°€ ë§¤ìš° í¼ ({max_files}). ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    )
                elif max_files < 100:
                    validation_result['warnings'].append(
                        f"max_filesê°€ ì‘ìŒ ({max_files}). ëŒ€í˜• í”„ë¡œì íŠ¸ì— ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    )
        
        # ì„œë²„ ì„¤ì • ê²€ì¦
        if 'server' in config:
            server = config['server']
            if 'port' in server:
                port = server['port']
                if port < 1024:
                    validation_result['warnings'].append(
                        f"í¬íŠ¸ {port}ëŠ” ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    )
                elif port > 65535:
                    validation_result['errors'].append(f"ì˜ëª»ëœ í¬íŠ¸ ë²ˆí˜¸: {port}")
                    validation_result['valid'] = False
        
        # LLM ì„¤ì • ê²€ì¦
        if 'llm' in config:
            llm = config['llm']
            if 'main_model' in llm:
                main_model = llm['main_model']
                if 'path' in main_model:
                    model_path = main_model['path']
                    if not validate_model_path(model_path):
                        validation_result['warnings'].append(
                            f"ë©”ì¸ ëª¨ë¸ ê²½ë¡œ í™•ì¸ í•„ìš”: {model_path}"
                        )
                        validation_result['recommendations'].append(
                            "python scripts/download_models.py ì‹¤í–‰ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                        )
        
        # ì„±ëŠ¥ ê¶Œì¥ì‚¬í•­
        if 'performance' in config:
            perf = config['performance']
            if 'gpu' in perf and perf['gpu'].get('enable', False):
                # GPU ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
                try:
                    import torch
                    if not torch.cuda.is_available():
                        validation_result['warnings'].append(
                            "GPUê°€ í™œì„±í™”ë˜ì–´ ìˆì§€ë§Œ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        )
                except ImportError:
                    validation_result['errors'].append(
                        "GPU ì„¤ì •ì´ í™œì„±í™”ë˜ì–´ ìˆì§€ë§Œ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                    )
        
    except Exception as e:
        validation_result['valid'] = False
        validation_result['errors'].append(f"ì„¤ì • ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    return validation_result

def check_system_requirements() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸"""
    requirements = {
        'python_version': {
            'required': '3.10+',
            'current': platform.python_version(),
            'status': 'unknown'
        },
        'memory': {
            'required_gb': 16,
            'recommended_gb': 32,
            'current_gb': 0,
            'status': 'unknown'
        },
        'disk_space': {
            'required_gb': 50,
            'recommended_gb': 200,
            'current_gb': 0,
            'status': 'unknown'
        },
        'cpu_cores': {
            'required': 4,
            'recommended': 8,
            'current': 0,
            'status': 'unknown'
        },
        'gpu': {
            'required': False,
            'available': False,
            'devices': [],
            'status': 'unknown'
        }
    }
    
    try:
        # Python ë²„ì „ í™•ì¸
        version_info = sys.version_info
        if version_info >= (3, 10):
            requirements['python_version']['status'] = 'ok'
        elif version_info >= (3, 8):
            requirements['python_version']['status'] = 'warning'
        else:
            requirements['python_version']['status'] = 'error'
        
        # ë©”ëª¨ë¦¬ í™•ì¸
        memory = psutil.virtual_memory()
        memory_gb = memory.total / (1024**3)
        requirements['memory']['current_gb'] = round(memory_gb, 1)
        
        if memory_gb >= 32:
            requirements['memory']['status'] = 'excellent'
        elif memory_gb >= 16:
            requirements['memory']['status'] = 'ok'
        elif memory_gb >= 8:
            requirements['memory']['status'] = 'warning'
        else:
            requirements['memory']['status'] = 'error'
        
        # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
        disk = psutil.disk_usage('.')
        disk_gb = disk.free / (1024**3)
        requirements['disk_space']['current_gb'] = round(disk_gb, 1)
        
        if disk_gb >= 200:
            requirements['disk_space']['status'] = 'excellent'
        elif disk_gb >= 50:
            requirements['disk_space']['status'] = 'ok'
        elif disk_gb >= 20:
            requirements['disk_space']['status'] = 'warning'
        else:
            requirements['disk_space']['status'] = 'error'
        
        # CPU í™•ì¸
        cpu_count = psutil.cpu_count(logical=False)
        requirements['cpu_cores']['current'] = cpu_count
        
        if cpu_count >= 16:
            requirements['cpu_cores']['status'] = 'excellent'
        elif cpu_count >= 8:
            requirements['cpu_cores']['status'] = 'ok'
        elif cpu_count >= 4:
            requirements['cpu_cores']['status'] = 'warning'
        else:
            requirements['cpu_cores']['status'] = 'error'
        
        # GPU í™•ì¸
        try:
            import torch
            if torch.cuda.is_available():
                requirements['gpu']['available'] = True
                requirements['gpu']['status'] = 'ok'
                
                for i in range(torch.cuda.device_count()):
                    props = torch.cuda.get_device_properties(i)
                    requirements['gpu']['devices'].append({
                        'id': i,
                        'name': props.name,
                        'memory_gb': round(props.total_memory / (1024**3), 1)
                    })
            else:
                requirements['gpu']['status'] = 'warning'
        except ImportError:
            requirements['gpu']['status'] = 'warning'
    
    except Exception as e:
        print(f"ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì˜¤ë¥˜: {e}")
    
    return requirements

def check_dependencies() -> Dict[str, Any]:
    """ì˜ì¡´ì„± íŒ¨í‚¤ì§€ í™•ì¸"""
    dependencies = {
        'critical': [
            'fastapi', 'uvicorn', 'pydantic', 'pydantic-settings'
        ],
        'important': [
            'torch', 'transformers', 'sentence-transformers'
        ],
        'optional': [
            'faiss-cpu', 'faiss-gpu', 'neo4j', 'networkx'
        ],
        'development': [
            'pytest', 'black', 'isort', 'mypy'
        ]
    }
    
    results = {
        'critical': {'installed': [], 'missing': []},
        'important': {'installed': [], 'missing': []},
        'optional': {'installed': [], 'missing': []},
        'development': {'installed': [], 'missing': []},
        'status': 'unknown'
    }
    
    for category, packages in dependencies.items():
        for package in packages:
            try:
                # íŒ¨í‚¤ì§€ëª… ì •ê·œí™”
                import_name = package.replace('-', '_')
                if import_name == 'pydantic_settings':
                    import_name = 'pydantic_settings'
                elif import_name == 'sentence_transformers':
                    import_name = 'sentence_transformers'
                
                __import__(import_name)
                results[category]['installed'].append(package)
            except ImportError:
                results[category]['missing'].append(package)
    
    # ì „ì²´ ìƒíƒœ ê²°ì •
    if results['critical']['missing']:
        results['status'] = 'error'
    elif results['important']['missing']:
        results['status'] = 'warning'
    else:
        results['status'] = 'ok'
    
    return results

def check_services() -> Dict[str, Any]:
    """ì™¸ë¶€ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    services = {
        'docker': {'status': 'unknown', 'version': None},
        'neo4j': {'status': 'unknown', 'accessible': False},
        'api_server': {'status': 'unknown', 'accessible': False}
    }
    
    # Docker í™•ì¸
    try:
        result = subprocess.run(
            ['docker', '--version'], 
            capture_output=True, 
            text=True, 
            timeout=5
        )
        if result.returncode == 0:
            services['docker']['status'] = 'ok'
            services['docker']['version'] = result.stdout.strip()
        else:
            services['docker']['status'] = 'error'
    except (subprocess.TimeoutExpired, FileNotFoundError):
        services['docker']['status'] = 'not_installed'
    
    # Neo4j í™•ì¸
    try:
        import requests
        response = requests.get(
            'http://localhost:7474',
            timeout=5
        )
        if response.status_code == 200:
            services['neo4j']['status'] = 'ok'
            services['neo4j']['accessible'] = True
        else:
            services['neo4j']['status'] = 'error'
    except Exception:
        services['neo4j']['status'] = 'not_running'
    
    # API ì„œë²„ í™•ì¸
    try:
        import requests
        response = requests.get(
            'http://localhost:8800/v1/health',
            timeout=5
        )
        if response.status_code == 200:
            services['api_server']['status'] = 'ok'
            services['api_server']['accessible'] = True
        else:
            services['api_server']['status'] = 'error'
    except Exception:
        services['api_server']['status'] = 'not_running'
    
    return services

def check_file_structure() -> Dict[str, Any]:
    """íŒŒì¼ êµ¬ì¡° í™•ì¸"""
    required_structure = {
        'directories': [
            'src', 'src/api', 'src/core', 'src/utils',
            'data', 'logs', 'scripts'
        ],
        'files': [
            'src/main.py', 'src/config.py',
            'requirements.txt', '.env.example',
            'docker-compose.yml'
        ],
        'optional_directories': [
            'data/models', 'data/vector_index', 'data/graph_db',
            'data/metadata', 'tests', 'static'
        ]
    }
    
    results = {
        'directories': {'present': [], 'missing': []},
        'files': {'present': [], 'missing': []},
        'optional_directories': {'present': [], 'missing': []},
        'status': 'unknown'
    }
    
    # í•„ìˆ˜ ë””ë ‰í† ë¦¬ í™•ì¸
    for directory in required_structure['directories']:
        if os.path.isdir(directory):
            results['directories']['present'].append(directory)
        else:
            results['directories']['missing'].append(directory)
    
    # í•„ìˆ˜ íŒŒì¼ í™•ì¸
    for file_path in required_structure['files']:
        if os.path.isfile(file_path):
            results['files']['present'].append(file_path)
        else:
            results['files']['missing'].append(file_path)
    
    # ì„ íƒì  ë””ë ‰í† ë¦¬ í™•ì¸
    for directory in required_structure['optional_directories']:
        if os.path.isdir(directory):
            results['optional_directories']['present'].append(directory)
        else:
            results['optional_directories']['missing'].append(directory)
    
    # ì „ì²´ ìƒíƒœ ê²°ì •
    if results['directories']['missing'] or results['files']['missing']:
        if len(results['directories']['missing']) > 2 or len(results['files']['missing']) > 2:
            results['status'] = 'error'
        else:
            results['status'] = 'warning'
    else:
        results['status'] = 'ok'
    
    return results

def run_comprehensive_validation() -> Dict[str, Any]:
    """ì¢…í•© ì‹œìŠ¤í…œ ê²€ì¦ ì‹¤í–‰"""
    print("ğŸ” Open CodeAI ì¢…í•© ì‹œìŠ¤í…œ ê²€ì¦ ì‹œì‘...")
    start_time = time.time()
    
    validation_results = {
        'timestamp': datetime.now().isoformat(),
        'overall_status': 'unknown',
        'summary': {},
        'details': {},
        'recommendations': [],
        'execution_time': 0
    }
    
    try:
        # 1. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸
        print("   ğŸ“‹ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì¤‘...")
        validation_results['details']['system_requirements'] = check_system_requirements()
        
        # 2. ì˜ì¡´ì„± íŒ¨í‚¤ì§€ í™•ì¸
        print("   ğŸ“¦ ì˜ì¡´ì„± íŒ¨í‚¤ì§€ í™•ì¸ ì¤‘...")
        validation_results['details']['dependencies'] = check_dependencies()
        
        # 3. íŒŒì¼ êµ¬ì¡° í™•ì¸
        print("   ğŸ“ íŒŒì¼ êµ¬ì¡° í™•ì¸ ì¤‘...")
        validation_results['details']['file_structure'] = check_file_structure()
        
        # 4. ì™¸ë¶€ ì„œë¹„ìŠ¤ í™•ì¸
        print("   ğŸ”§ ì™¸ë¶€ ì„œë¹„ìŠ¤ í™•ì¸ ì¤‘...")
        validation_results['details']['services'] = check_services()
        
        # 5. ì„¤ì • íŒŒì¼ ê²€ì¦
        print("   âš™ï¸ ì„¤ì • íŒŒì¼ ê²€ì¦ ì¤‘...")
        try:
            from ..config import settings
            config_dict = {
                'project': {},  # settings.project ì œê±°
                'server': settings.server.dict() if hasattr(settings, 'server') else {},
                'llm': settings.llm.dict() if hasattr(settings, 'llm') else {}
            }
            validation_results['details']['config_validation'] = validate_config(config_dict)
        except Exception as e:
            validation_results['details']['config_validation'] = {
                'valid': False,
                'errors': [f"ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {str(e)}"]
            }
        
        # 6. ëª¨ë¸ íŒŒì¼ í™•ì¸
        print("   ğŸ¤– AI ëª¨ë¸ í™•ì¸ ì¤‘...")
        model_status = {'main_model': False, 'embedding_model': False}
        
        try:
            from ..config import settings
            if hasattr(settings, 'llm') and settings.llm:
                if hasattr(settings.llm, 'main_model'):
                    model_status['main_model'] = validate_model_path(settings.llm.main_model.path)
                if hasattr(settings.llm, 'embedding_model'):
                    model_status['embedding_model'] = validate_model_path(settings.llm.embedding_model.path)
        except Exception:
            pass
        
        validation_results['details']['models'] = model_status
        
        # 7. ì „ì²´ ìƒíƒœ ê²°ì •
        status_scores = []
        
        # ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ì ìˆ˜
        sys_req = validation_results['details']['system_requirements']
        critical_reqs = ['python_version', 'memory', 'disk_space']
        sys_score = sum(1 for req in critical_reqs 
                       if sys_req[req]['status'] in ['ok', 'excellent']) / len(critical_reqs)
        status_scores.append(('system', sys_score))
        
        # ì˜ì¡´ì„± ì ìˆ˜
        deps = validation_results['details']['dependencies']
        if deps['status'] == 'ok':
            dep_score = 1.0
        elif deps['status'] == 'warning':
            dep_score = 0.7
        else:
            dep_score = 0.3
        status_scores.append(('dependencies', dep_score))
        
        # íŒŒì¼ êµ¬ì¡° ì ìˆ˜
        files = validation_results['details']['file_structure']
        if files['status'] == 'ok':
            file_score = 1.0
        elif files['status'] == 'warning':
            file_score = 0.8
        else:
            file_score = 0.4
        status_scores.append(('files', file_score))
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        overall_score = sum(score for _, score in status_scores) / len(status_scores)
        
        if overall_score >= 0.9:
            validation_results['overall_status'] = 'healthy'
        elif overall_score >= 0.7:
            validation_results['overall_status'] = 'caution'
        elif overall_score >= 0.5:
            validation_results['overall_status'] = 'warning'
        else:
            validation_results['overall_status'] = 'critical'
        
        # 8. ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = []
        
        # ì‹œìŠ¤í…œ ê¶Œì¥ì‚¬í•­
        if sys_req['memory']['status'] == 'warning':
            recommendations.append("ë©”ëª¨ë¦¬ë¥¼ 16GB ì´ìƒìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        if sys_req['gpu']['status'] == 'warning':
            recommendations.append("GPUë¥¼ ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.")
        
        # ì˜ì¡´ì„± ê¶Œì¥ì‚¬í•­
        if deps['critical']['missing']:
            recommendations.append(f"í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install {' '.join(deps['critical']['missing'])}")
        
        if deps['important']['missing']:
            recommendations.append(f"ì¤‘ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install {' '.join(deps['important']['missing'])}")
        
        # ëª¨ë¸ ê¶Œì¥ì‚¬í•­
        if not model_status['main_model']:
            recommendations.append("AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: python scripts/download_models.py")
        
        # ì„œë¹„ìŠ¤ ê¶Œì¥ì‚¬í•­
        services = validation_results['details']['services']
        if services['docker']['status'] == 'not_installed':
            recommendations.append("Docker ì„¤ì¹˜ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤ (Neo4j ì‚¬ìš©ì„ ìœ„í•´)")
        
        if services['neo4j']['status'] == 'not_running':
            recommendations.append("Neo4j ì‹œì‘: docker-compose up -d neo4j")
        
        validation_results['recommendations'] = recommendations
        
        # 9. ìš”ì•½ ì •ë³´ ìƒì„±
        validation_results['summary'] = {
            'overall_score': round(overall_score * 100, 1),
            'critical_issues': sum(1 for _, score in status_scores if score < 0.5),
            'warnings': sum(1 for _, score in status_scores if 0.5 <= score < 0.8),
            'recommendations_count': len(recommendations),
            'models_ready': sum(model_status.values()),
            'services_running': sum(1 for service in services.values() if service['status'] == 'ok')
        }
        
        validation_results['execution_time'] = round(time.time() - start_time, 2)
        
        print(f"âœ… ê²€ì¦ ì™„ë£Œ ({validation_results['execution_time']}ì´ˆ)")
        
    except Exception as e:
        validation_results['overall_status'] = 'error'
        validation_results['details']['validation_error'] = str(e)
        validation_results['execution_time'] = round(time.time() - start_time, 2)
        print(f"âŒ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    return validation_results

def generate_validation_report(results: Dict[str, Any]) -> str:
    """ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
    
    def status_icon(status: str) -> str:
        icons = {
            'ok': 'âœ…', 'excellent': 'ğŸŒŸ', 'warning': 'âš ï¸', 
            'error': 'âŒ', 'critical': 'ğŸš¨', 'unknown': 'â“',
            'not_installed': 'ğŸ“‹', 'not_running': 'ğŸ’¤',
            'healthy': 'ğŸŸ¢', 'caution': 'ğŸŸ¡'
        }
        return icons.get(status, 'â“')
    
    report = []
    report.append("=" * 80)
    report.append("ğŸ” OPEN CODEAI ì‹œìŠ¤í…œ ê²€ì¦ ë¦¬í¬íŠ¸")
    report.append("=" * 80)
    
    # ê¸°ë³¸ ì •ë³´
    report.append(f"ğŸ“… ê²€ì¦ ì‹œê°: {results['timestamp']}")
    report.append(f"â±ï¸  ì‹¤í–‰ ì‹œê°„: {results['execution_time']}ì´ˆ")
    report.append(f"ğŸ¯ ì „ì²´ ìƒíƒœ: {status_icon(results['overall_status'])} {results['overall_status'].upper()}")
    
    if 'summary' in results:
        summary = results['summary']
        report.append(f"ğŸ“Š ì „ì²´ ì ìˆ˜: {summary['overall_score']}%")
        report.append(f"ğŸš¨ ì‹¬ê°í•œ ë¬¸ì œ: {summary['critical_issues']}ê°œ")
        report.append(f"âš ï¸  ê²½ê³ : {summary['warnings']}ê°œ")
        report.append(f"ğŸ¤– ì¤€ë¹„ëœ ëª¨ë¸: {summary['models_ready']}/2ê°œ")
        report.append(f"ğŸ”§ ì‹¤í–‰ ì¤‘ì¸ ì„œë¹„ìŠ¤: {summary['services_running']}ê°œ")
    
    report.append("")
    
    # ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­
    if 'system_requirements' in results['details']:
        report.append("ğŸ’» ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­")
        report.append("-" * 40)
        
        sys_req = results['details']['system_requirements']
        
        report.append(f"ğŸ Python: {status_icon(sys_req['python_version']['status'])} "
                     f"{sys_req['python_version']['current']} (ìš”êµ¬: {sys_req['python_version']['required']})")
        
        report.append(f"ğŸ’¾ ë©”ëª¨ë¦¬: {status_icon(sys_req['memory']['status'])} "
                     f"{sys_req['memory']['current_gb']}GB (ê¶Œì¥: {sys_req['memory']['recommended_gb']}GB)")
        
        report.append(f"ğŸ’¿ ë””ìŠ¤í¬: {status_icon(sys_req['disk_space']['status'])} "
                     f"{sys_req['disk_space']['current_gb']}GB (ê¶Œì¥: {sys_req['disk_space']['recommended_gb']}GB)")
        
        report.append(f"ğŸ–¥ï¸  CPU: {status_icon(sys_req['cpu_cores']['status'])} "
                     f"{sys_req['cpu_cores']['current']}ì½”ì–´ (ê¶Œì¥: {sys_req['cpu_cores']['recommended']}ì½”ì–´)")
        
        gpu_info = sys_req['gpu']
        gpu_text = f"ğŸ® GPU: {status_icon(gpu_info['status'])}"
        if gpu_info['available']:
            gpu_names = [dev['name'] for dev in gpu_info['devices']]
            gpu_text += f" {', '.join(gpu_names)}"
        else:
            gpu_text += " ì‚¬ìš© ë¶ˆê°€"
        report.append(gpu_text)
        
        report.append("")
    
    # ì˜ì¡´ì„± íŒ¨í‚¤ì§€
    if 'dependencies' in results['details']:
        report.append("ğŸ“¦ ì˜ì¡´ì„± íŒ¨í‚¤ì§€")
        report.append("-" * 40)
        
        deps = results['details']['dependencies']
        categories = ['critical', 'important', 'optional']
        
        for category in categories:
            if category in deps:
                cat_data = deps[category]
                installed_count = len(cat_data['installed'])
                missing_count = len(cat_data['missing'])
                total = installed_count + missing_count
                
                category_icon = 'ğŸ”´' if missing_count > 0 and category == 'critical' else \
                               'ğŸŸ¡' if missing_count > 0 and category == 'important' else 'ğŸŸ¢'
                
                report.append(f"{category_icon} {category.title()}: {installed_count}/{total} ì„¤ì¹˜ë¨")
                
                if cat_data['missing']:
                    report.append(f"   âŒ ëˆ„ë½: {', '.join(cat_data['missing'])}")
        
        report.append("")
    
    # íŒŒì¼ êµ¬ì¡°
    if 'file_structure' in results['details']:
        report.append("ğŸ“ íŒŒì¼ êµ¬ì¡°")
        report.append("-" * 40)
        
        files = results['details']['file_structure']
        report.append(f"{status_icon(files['status'])} ì „ì²´ ìƒíƒœ: {files['status']}")
        
        if files['directories']['missing']:
            report.append(f"âŒ ëˆ„ë½ëœ ë””ë ‰í† ë¦¬: {', '.join(files['directories']['missing'])}")
        
        if files['files']['missing']:
            report.append(f"âŒ ëˆ„ë½ëœ íŒŒì¼: {', '.join(files['files']['missing'])}")
        
        report.append("")
    
    # ì™¸ë¶€ ì„œë¹„ìŠ¤
    if 'services' in results['details']:
        report.append("ğŸ”§ ì™¸ë¶€ ì„œë¹„ìŠ¤")
        report.append("-" * 40)
        
        services = results['details']['services']
        
        for service_name, service_data in services.items():
            status = service_data['status']
            report.append(f"{status_icon(status)} {service_name.title()}: {status}")
            
            if service_name == 'docker' and service_data.get('version'):
                report.append(f"   ğŸ“‹ ë²„ì „: {service_data['version']}")
        
        report.append("")
    
    # AI ëª¨ë¸
    if 'models' in results['details']:
        report.append("ğŸ¤– AI ëª¨ë¸")
        report.append("-" * 40)
        
        models = results['details']['models']
        
        for model_name, is_ready in models.items():
            icon = 'âœ…' if is_ready else 'âŒ'
            status = 'ì¤€ë¹„ë¨' if is_ready else 'ëˆ„ë½'
            report.append(f"{icon} {model_name}: {status}")
        
        report.append("")
    
    # ì„¤ì • ê²€ì¦
    if 'config_validation' in results['details']:
        report.append("âš™ï¸ ì„¤ì • ê²€ì¦")
        report.append("-" * 40)
        
        config = results['details']['config_validation']
        
        if config.get('valid', False):
            report.append("âœ… ì„¤ì • íŒŒì¼ì´ ìœ íš¨í•©ë‹ˆë‹¤")
        else:
            report.append("âŒ ì„¤ì • íŒŒì¼ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤")
        
        if config.get('errors'):
            report.append("ğŸš¨ ì˜¤ë¥˜:")
            for error in config['errors']:
                report.append(f"   â€¢ {error}")
        
        if config.get('warnings'):
            report.append("âš ï¸ ê²½ê³ :")
            for warning in config['warnings']:
                report.append(f"   â€¢ {warning}")
        
        report.append("")
    
    # ê¶Œì¥ì‚¬í•­
    if results.get('recommendations'):
        report.append("ğŸ’¡ ê¶Œì¥ì‚¬í•­")
        report.append("-" * 40)
        
        for i, recommendation in enumerate(results['recommendations'], 1):
            report.append(f"{i}. {recommendation}")
        
        report.append("")
    
    # ë‹¤ìŒ ë‹¨ê³„
    report.append("ğŸš€ ë‹¤ìŒ ë‹¨ê³„")
    report.append("-" * 40)
    
    status = results['overall_status']
    
    if status == 'healthy':
        report.append("ğŸ‰ ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        report.append("   ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì„œë²„ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        report.append("   ./start.sh")
        report.append("")
        report.append("   Continue.dev ì„¤ì •:")
        report.append("   1. VS Codeì—ì„œ Continue í™•ì¥ ì„¤ì¹˜")
        report.append("   2. ì„¤ì • íŒŒì¼ ë³µì‚¬: cp examples/continue_config.json ~/.continue/config.json")
        report.append("   3. Ctrl+Shift+Lë¡œ ì±„íŒ… ì‹œì‘")
    
    elif status == 'caution':
        report.append("âš ï¸ ì‹œìŠ¤í…œì´ ëŒ€ì²´ë¡œ ì •ìƒì´ì§€ë§Œ ì¼ë¶€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        report.append("   ìœ„ì˜ ê¶Œì¥ì‚¬í•­ì„ í™•ì¸í•˜ì—¬ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        report.append("   ê¸°ë³¸ ê¸°ëŠ¥ì€ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤: ./start.sh")
    
    elif status == 'warning':
        report.append("ğŸ”§ ì—¬ëŸ¬ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ìˆœì„œë¡œ í•´ê²°í•˜ì„¸ìš”:")
        report.append("   1. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install -r requirements.txt")
        report.append("   2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: python scripts/download_models.py")
        report.append("   3. Docker ì„œë¹„ìŠ¤ ì‹œì‘: docker-compose up -d")
        report.append("   4. ì¬ê²€ì¦: python scripts/system_check.py --detailed")
    
    else:  # critical or error
        report.append("ğŸš¨ ì‹¬ê°í•œ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ í•´ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤:")
        report.append("   1. Python ê°€ìƒí™˜ê²½ í™•ì¸: source venv/bin/activate")
        report.append("   2. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ (ë©”ëª¨ë¦¬, ë””ìŠ¤í¬ ê³µê°„)")
        report.append("   3. ì„¤ì¹˜ ê°€ì´ë“œ ì°¸ì¡°: README.md")
        report.append("   4. ë¬¸ì œ ì§€ì†ì‹œ ì´ìŠˆ ìƒì„±: https://github.com/ChangooLee/open-codeai/issues")
    
    report.append("")
    report.append("=" * 80)
    report.append("ê²€ì¦ ì™„ë£Œ")
    report.append("=" * 80)
    
    return "\n".join(report)